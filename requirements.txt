safetensors==0.4.2
transformers==4.39.3
streamlit==1.41.1
git+https://github.com/Dao-AILab/flash-attention.git
